{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager Execution: True\n",
      "TensorFlow version: 2.0.0-alpha0\n",
      "Eager execution is: True\n",
      "Keras version: 2.2.4-tf\n",
      "Running on CPU\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install --user --upgrade pip\n",
    "# !pip install --user -q tensorflow==2.0.0-alpha0\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "print(\"Eager Execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution is: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))\n",
    "\n",
    "# Install a temporary patch to enable a few extra TF 2.0 upgrades. This piece will be removed soon.\n",
    "\n",
    "from tensorflow.python.ops import control_flow_util\n",
    "control_flow_util.ENABLE_CONTROL_FLOW_V2 = True\n",
    "\n",
    "#@tf.function\n",
    "var = tf.Variable([3, 3])\n",
    "\n",
    "if tf.test.is_gpu_available(): \n",
    "    print('Running on GPU')\n",
    "    print('GPU #0?')\n",
    "    print(var.device.endswith('GPU:0'))\n",
    "else: \n",
    "    print('Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Data\n",
    "\n",
    "x_train, y_train = tf.cast(x_train/255., dtype=tf.float32), tf.cast(y_train/255., tf.float32)\n",
    "x_test, y_test = tf.cast(x_test/255., dtype=tf.float32), tf.cast(y_test/255., tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Dataset to represent an input Pipline\n",
    "\n",
    "# https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays\n",
    "ds_train = tf.data.Dataset.from_tensor_slices( (x_train, y_train) ).batch(32).shuffle(8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.ShuffleDataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(lambda x, y: (tf.image.random_flip_left_right(x), y))   # 隨機水平翻轉影像，加強資料差異, 但標籤 y 不變"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.repeat()  #無限重複"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size).shuffle(8888)\n",
    "ds_test = ds_test.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    " tf.keras.layers.Flatten(),\n",
    " tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    " tf.keras.layers.Dropout(0.3),\n",
    " tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When passing an infinitely repeating dataset, you must specify the `steps_per_epoch` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-91baef5e26fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;31m# Case 3: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[0mreset_dataset_after_each_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m       steps_per_epoch = training_utils.infer_steps_for_dataset(\n\u001b[0;32m--> 132\u001b[0;31m           data, steps_per_epoch, epochs=epochs, steps_name=steps_name)\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# Convert to a format that supports `next(generator)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36minfer_steps_for_dataset\u001b[0;34m(dataset, steps, epochs, steps_name)\u001b[0m\n\u001b[1;32m   1444\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFINITE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m     raise ValueError('When passing an infinitely repeating dataset, you '\n\u001b[0;32m-> 1446\u001b[0;31m                      'must specify the `%s` argument.' % (steps_name,))\n\u001b[0m\u001b[1;32m   1447\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: When passing an infinitely repeating dataset, you must specify the `steps_per_epoch` argument."
     ]
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0026 - accuracy: 0.1002\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 8.3612e-07 - accuracy: 0.0998\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 2.5427e-07 - accuracy: 0.0999\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 8.5586e-08 - accuracy: 0.0998\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 6.0206e-08 - accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 1.0570e-08 - accuracy: 0.0998\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 8.8390e-09 - accuracy: 0.0992\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 4.1841e-09 - accuracy: 0.1001\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 1.0709e-09 - accuracy: 0.0992\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 3.1748e-09 - accuracy: 0.0981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb6152f2b70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(x_train) // batch_size\n",
    "\n",
    "model.fit(ds_train, epochs=epochs, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.115625]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
